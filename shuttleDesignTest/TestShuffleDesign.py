
import numpy as np
import tensorflow as tf
from keras import layers, regularizers
from keras.backend import concatenate
from matplotlib import pyplot as plt
from keras.layers import SimpleRNN, Input
from keras.optimizers import SGD, Adam

from CTRNNLIB import GenericFunctions
from CTRNNLIB.Recurrent import SimpleMEMSCTRNN
from CTRNNLIB.Recurrent import ShuttleCTRNN
from CTRNNLIB.shuttleDesignTest.Generate_Data_Module import generate_training_data


def train_deniosing_problem_rnn_window_size10_stateful_seq_to_seq(factor=1, window_size=10, shift=0):
    number_of_features = 1
    batch_size_=1

    # Generate some example data

    x_train, y_train=generate_training_data(window_size=window_size, num_of_generator=10,enviroment_end_time=10*3392*10**-6)



    x_train = factor * x_train+shift
    y_train = factor * y_train+shift
    input_layer = Input(batch_shape= (batch_size_,window_size,number_of_features),
                       name="input")
    stateful_arg=True

    arg_vb = 10
    arg_input_gain = 1
    arg_output_gain = 10**7

    cell1 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1, stddev=0.05, seed=1))(input_layer)
    cell2 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=2, stddev=0.05, seed=2))(input_layer)
    cell3 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.5, stddev=0.05, seed=3))(input_layer)
    cell4 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.75, stddev=0.05, seed=4))(input_layer)
    cell5 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.1, stddev=0.05, seed=100))(input_layer)


    rnn_1 = concatenate([cell1, cell2, cell3, cell4, cell5])

    hidden_1 = layers.TimeDistributed(layers.Dense(5, activation='sigmoid'))(rnn_1)
    output_ = layers.TimeDistributed(layers.Dense(1, activation='linear'))(hidden_1)

    model = tf.keras.Model(inputs=input_layer, outputs=output_)  # output list [output_,...]

    model.compile(loss='mae',
                  optimizer=Adam(learning_rate=0.001),
                  metrics=['mse'],

                  )
    n_epochs = 6
    for i in range(n_epochs):
        print("Epoch:", i + 1)
        for j in range(len(x_train)):
            model.fit(x_train[j], y_train[j], epochs=1, batch_size=batch_size_, shuffle=False)

            model.reset_states()
            print("Reset State")
    model.save_weights('../../models/shuttle_design_model.h5')
    model.summary()
    for layer in model.layers:
        weights = layer.get_weights()
        print(weights)
        print("*" * 100)
    print("-" * 300)
    # get_weights_custom_function(model, [5, 2, 1])

    x_test, y_test = generate_training_data(window_size=window_size, num_of_generator=1,enviroment_end_time=5*3392*10**-6)
    x_test=x_test.reshape(x_test.shape[1], window_size, number_of_features)
    y_test=y_test.reshape(y_test.shape[1], window_size, number_of_features)

    x_test = factor * x_test + shift
    y_test = factor * y_test + shift

    output=model.predict(x_test,batch_size=batch_size_)
    plt.plot(y_test.reshape(-1),'r',alpha=1)
    plt.plot(x_test.reshape(-1),'g',alpha=.6)
    plt.xlabel("time*10^-6")
    plt.ylabel("voltage")
    plt.title("blue:Predicted Signal, Red: Ground Truth, Green:Noised Signal")


    plt.plot(output.reshape(-1), 'b',alpha=.8)
    plt.show()

    #testMode_modified(model, factor, shift=shift, window_size=window_size, batch_size=batch_size_)
def test_deniosing_problem_rnn_window_size10_stateful_seq_to_seq(factor=1, window_size=10, shift=0,model_path="../../models/shuttle_model_working_10windowsize.h5"):
    number_of_features = 1
    batch_size_=1

    # Generate some example data


    # Any RNN layer in Keras expects a 3D shape (batch_size, timesteps, features). This means you have timeseries data.
    input_layer = Input(batch_shape= (batch_size_,window_size,number_of_features),
                       name="input")
    #input_layer = Input((window_size, 1))
    stateful_arg=True
    arg_vb = 10
    arg_input_gain = 1
    arg_output_gain = 10**7
    #arg_output_gain = 10**0

    cell1 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1, stddev=0.05, seed=1))(input_layer)
    cell2 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=2, stddev=0.05, seed=2))(input_layer)
    cell3 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.5, stddev=0.05, seed=3))(input_layer)
    cell4 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.75, stddev=0.05, seed=4))(input_layer)
    cell5 = ShuttleCTRNN(1, vb=arg_vb, bias_initializer=tf.initializers.Zeros(), return_sequences=True, stateful=stateful_arg,
                         input_gain=arg_input_gain, output_gain=arg_output_gain,
                         recurrent_initializer=tf.keras.initializers.RandomNormal(mean=1.1, stddev=0.05, seed=100))(input_layer)

    #
    rnn_1 = concatenate([cell1, cell2, cell3, cell4, cell5])


    hidden_1 = layers.TimeDistributed(layers.Dense(5, activation='sigmoid'))(rnn_1)
    output_ = layers.TimeDistributed(layers.Dense(1, activation='linear'))(hidden_1)

    model = tf.keras.Model(inputs=input_layer, outputs=output_)  # output list [output_,...]

    model.compile(loss='mae',
                  optimizer=SGD(learning_rate=0.001),
                  metrics=['mse'],

                  )
    # train the network
    model.load_weights(model_path)
    model.summary()
    for layer in model.layers:
        weights = layer.get_weights()
        print(weights)
        print("*" * 100)
    print("-" * 300)
    # get_weights_custom_function(model, [5, 2, 1])

    x_test, y_test = generate_training_data(window_size=window_size, num_of_generator=1,enviroment_end_time=5*3392*10**-6)
    x_test=x_test.reshape(x_test.shape[1], window_size, number_of_features)
    y_test=y_test.reshape(y_test.shape[1], window_size, number_of_features)

    x_test = factor * x_test + shift
    y_test = factor * y_test + shift

    output=model.predict(x_test,batch_size=batch_size_)
    plt.plot(y_test.reshape(-1),'r',alpha=1)
    plt.plot(x_test.reshape(-1),'g',alpha=.6)
    plt.xlabel("time*10^-6")
    plt.ylabel("voltage")
    plt.title("blue:Predicted Signal, Red: Ground Truth, Green:Noised Signal")



    plt.plot(output.reshape(-1), 'b',alpha=.8)
    plt.show()
    import pandas as pd
    excel_array=np.array([y_test.reshape(-1), x_test.reshape(-1),output.reshape(-1)])
    excel_array=np.transpose(excel_array)
    df = pd.DataFrame(excel_array,columns=['Ground Truth', 'Noised Signal', 'Model Output'])
    df.to_csv('./output/file.csv', index=False)

















if __name__ == '__main__':
    print('hi main')


    train_deniosing_problem_rnn_window_size10_stateful_seq_to_seq(factor=1, window_size=10, shift=0)
    test_deniosing_problem_rnn_window_size10_stateful_seq_to_seq(factor=1,window_size=10,shift=0)
